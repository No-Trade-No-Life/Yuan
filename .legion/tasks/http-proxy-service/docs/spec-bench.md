# Bench Spec: HTTP Proxy Service Performance Benchmarks

**åŸºäº**: Dev Spec - HTTP Proxy Service Implementation  
**ç›®æ ‡è¯»è€…**: æ€§èƒ½å·¥ç¨‹å¸ˆã€SRE  
**çŠ¶æ€**: Ready for Implementation

---

## 1. Benchmark ç›®æ ‡

### 1.1 æ€§èƒ½æŒ‡æ ‡

- **ååé‡ï¼ˆThroughputï¼‰**: æ¯ç§’å¤„ç†çš„è¯·æ±‚æ•°ï¼ˆRPSï¼‰
- **å»¶è¿Ÿï¼ˆLatencyï¼‰**: P50, P95, P99 å“åº”æ—¶é—´
- **å¹¶å‘èƒ½åŠ›ï¼ˆConcurrencyï¼‰**: åŒæ—¶å¤„ç†çš„è¯·æ±‚æ•°ä¸Šé™
- **èµ„æºæ¶ˆè€—ï¼ˆResource Usageï¼‰**: CPUã€å†…å­˜å ç”¨

### 1.2 åŸºå‡†åœºæ™¯

| åœºæ™¯           | æè¿°                     | ç›®æ ‡             |
| -------------- | ------------------------ | ---------------- |
| **è½»é‡çº§è¯·æ±‚** | GET å°æ–‡ä»¶ï¼ˆ\u003c 1KBï¼‰ | \u003e 500 RPS   |
| **ä¸­ç­‰è´Ÿè½½**   | POST JSONï¼ˆ~10KBï¼‰       | \u003e 200 RPS   |
| **é‡è´Ÿè½½**     | GET å¤§æ–‡ä»¶ï¼ˆ~1MBï¼‰       | \u003e 50 RPS    |
| **é«˜å¹¶å‘**     | 100 å¹¶å‘è¯·æ±‚             | P95 \u003c 500ms |

---

## 2. Benchmark å·¥å…·

### 2.1 å·¥å…·é€‰æ‹©

- **autocannon**: Node.js HTTP å‹æµ‹å·¥å…·
- **clinic.js**: æ€§èƒ½åˆ†æï¼ˆCPUã€Memoryã€Event Loopï¼‰
- **0x**: Flame graph ç”Ÿæˆå™¨

### 2.2 å®‰è£…ä¾èµ–

```bash
npm install --save-dev autocannon clinic 0x
```

---

## 3. Benchmark å®ç°

### 3.1 åŸºç¡€è®¾æ–½æ­å»º

**æ–‡ä»¶è·¯å¾„**: `benchmarks/setup.ts`

```typescript
import { Terminal } from '@yuants/protocol';
import { provideHTTPProxyService } from '../src/server';
import http from 'http';

/**
 * å¯åŠ¨æœ¬åœ° HTTP æµ‹è¯•æœåŠ¡å™¨
 */
export const startTestServer = (port: number = 3000): http.Server => {
  const server = http.createServer((req, res) => {
    const url = new URL(req.url!, `http://localhost:${port}`);

    // è½»é‡çº§å“åº”
    if (url.pathname === '/light') {
      res.writeHead(200, { 'Content-Type': 'text/plain' });
      res.end('OK');
      return;
    }

    // ä¸­ç­‰è´Ÿè½½å“åº”
    if (url.pathname === '/medium') {
      const data = { message: 'test', data: 'x'.repeat(10000) };
      res.writeHead(200, { 'Content-Type': 'application/json' });
      res.end(JSON.stringify(data));
      return;
    }

    // é‡è´Ÿè½½å“åº”
    if (url.pathname === '/heavy') {
      res.writeHead(200, { 'Content-Type': 'application/octet-stream' });
      res.end(Buffer.alloc(1024 * 1024, 'x')); // 1MB
      return;
    }

    res.writeHead(404);
    res.end('Not Found');
  });

  server.listen(port);
  return server;
};

/**
 * å¯åŠ¨ä»£ç†èŠ‚ç‚¹
 */
export const startProxyTerminal = async (hostUrl: string): Promise<Terminal> => {
  const terminal = new Terminal(hostUrl, {
    terminal_id: 'bench-proxy',
  });

  provideHTTPProxyService(
    terminal,
    {
      benchmark: 'true',
      region: 'local',
    },
    {
      concurrent: 100, // å…è®¸ 100 å¹¶å‘
    },
  );

  // ç­‰å¾…æœåŠ¡æ³¨å†Œ
  await new Promise((resolve) => setTimeout(resolve, 1000));

  return terminal;
};

/**
 * å¯åŠ¨å®¢æˆ·ç«¯
 */
export const startClientTerminal = async (hostUrl: string): Promise<Terminal> => {
  const terminal = new Terminal(hostUrl, {
    terminal_id: 'bench-client',
  });

  await terminal.client.servicesReady();

  return terminal;
};
```

---

### 3.2 Benchmark Suite

**æ–‡ä»¶è·¯å¾„**: `benchmarks/index.ts`

```typescript
import autocannon from 'autocannon';
import { startTestServer, startProxyTerminal, startClientTerminal } from './setup';
import { requestHTTPProxy } from '../src/client';
import { IHTTPProxyRequest } from '../src/types';

const DEFAULT_HOST_URL = process.env.HOST_URL;
const TEST_SERVER_PORT = 3000;

async function main() {
  console.log('ğŸš€ Starting HTTP Proxy Service Benchmark...\n');

  // 1. å¯åŠ¨æµ‹è¯•æœåŠ¡å™¨
  const testServer = startTestServer(TEST_SERVER_PORT);
  console.log(`âœ… Test server listening on :${TEST_SERVER_PORT}`);

  // 2. å¯åŠ¨ Hostï¼ˆè‹¥æœªæä¾› HOST_URLï¼‰
  const hostProcess = DEFAULT_HOST_URL ? null : await startHostProcess();
  const hostUrl = DEFAULT_HOST_URL || hostProcess!.hostUrl;

  // 3. å¯åŠ¨ä»£ç†èŠ‚ç‚¹
  const proxyTerminal = await startProxyTerminal(hostUrl);
  console.log('âœ… Proxy terminal ready');

  // 4. å¯åŠ¨å®¢æˆ·ç«¯
  const clientTerminal = await startClientTerminal(hostUrl);
  console.log('âœ… Client terminal ready\n');

  // 4. è¿è¡Œ benchmarks
  await runBenchmarks(clientTerminal);

  // 5. æ¸…ç†
  testServer.close();
  proxyTerminal.dispose();
  clientTerminal.dispose();
  if (hostProcess) {
    await stopHostProcess(hostProcess.process);
  }

  console.log('\nâœ… Benchmark complete!');
  process.exit(0);
}

async function runBenchmarks(clientTerminal: Terminal) {
  const scenarios = [
    {
      name: 'Light Load (GET \u003c1KB)',
      request: {
        url: `http://localhost:${TEST_SERVER_PORT}/light`,
        method: 'GET' as const,
      },
    },
    {
      name: 'Medium Load (POST ~10KB)',
      request: {
        url: `http://localhost:${TEST_SERVER_PORT}/medium`,
        method: 'GET' as const,
      },
    },
    {
      name: 'Heavy Load (GET ~1MB)',
      request: {
        url: `http://localhost:${TEST_SERVER_PORT}/heavy`,
        method: 'GET' as const,
      },
    },
  ];

  for (const scenario of scenarios) {
    console.log(`\nğŸ“Š Running: ${scenario.name}`);
    console.log('â”€'.repeat(60));

    await benchmarkRequest(clientTerminal, scenario.request);
  }
}

async function benchmarkRequest(clientTerminal: Terminal, request: IHTTPProxyRequest) {
  const startTime = Date.now();
  const iterations = 1000;
  const concurrency = 10;

  // é¢„çƒ­
  await requestHTTPProxy(clientTerminal, request);

  // å¹¶å‘æ‰§è¡Œ
  const batches = Math.ceil(iterations / concurrency);
  const latencies: number[] = [];

  for (let i = 0; i < batches; i++) {
    const batchRequests = Array.from({ length: concurrency }, async () => {
      const reqStart = Date.now();
      await requestHTTPProxy(clientTerminal, request);
      const reqEnd = Date.now();
      return reqEnd - reqStart;
    });

    const batchLatencies = await Promise.all(batchRequests);
    latencies.push(...batchLatencies);
  }

  const totalTime = Date.now() - startTime;

  // ç»Ÿè®¡
  latencies.sort((a, b) => a - b);
  const p50 = latencies[Math.floor(latencies.length * 0.5)];
  const p95 = latencies[Math.floor(latencies.length * 0.95)];
  const p99 = latencies[Math.floor(latencies.length * 0.99)];
  const avg = latencies.reduce((a, b) => a + b, 0) / latencies.length;
  const rps = (iterations / totalTime) * 1000;

  console.log(`Requests:    ${iterations}`);
  console.log(`Duration:    ${totalTime}ms`);
  console.log(`RPS:         ${rps.toFixed(2)}`);
  console.log(`Latency:`);
  console.log(`  Avg:       ${avg.toFixed(2)}ms`);
  console.log(`  P50:       ${p50}ms`);
  console.log(`  P95:       ${p95}ms`);
  console.log(`  P99:       ${p99}ms`);
}

main().catch(console.error);
```

---

### 3.3 Selector å¾®åŸºå‡†

**ç›®æ ‡**ï¼šè¯„ä¼° `selectHTTPProxyIpRoundRobin` åœ¨ä¸åŒ proxy æ± è§„æ¨¡ä¸‹çš„æ€§èƒ½å¼€é”€ã€‚

**åœºæ™¯**ï¼š

| åœºæ™¯ | Proxy æ± è§„æ¨¡ | è¿­ä»£æ¬¡æ•° | ç›®æ ‡ (RPS) |
| ---- | ------------ | -------- | ---------- |
| S1   | 1            | 20000    | >= 100000  |
| S2   | 16           | 20000    | >= 80000   |
| S3   | 128          | 20000    | >= 60000   |
| S4   | 1024         | 20000    | >= 40000   |

**è¾“å‡ºè¦æ±‚**ï¼š

- æ§åˆ¶å°è¾“å‡ºä¸ç°æœ‰ bench é£æ ¼ä¸€è‡´ï¼ˆRequests/Duration/RPS/Latency/Thresholds/Resultï¼‰
- æ¯ä¸ªåœºæ™¯è¾“å‡º `ResultJSON`ï¼ŒåŒ…å« `poolSize`ã€`rps`ã€`p50Ms/p95Ms/p99Ms`ã€`threshold`ã€`pass`

**é˜ˆå€¼åˆ¤å®š**ï¼š

- ä»»ä¸€åœºæ™¯æœªè¾¾æ ‡æ—¶æ•´ä½“ bench å¤±è´¥ï¼ˆè¿›ç¨‹é€€å‡ºç ä¸º 1ï¼‰

---

### 3.4 è¿è¡Œè„šæœ¬

**æ–‡ä»¶è·¯å¾„**: `package.json`

**ç¯å¢ƒå˜é‡**ï¼š

- `HOST_URL`ï¼šå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨å¯åŠ¨æœ¬åœ° Hostã€‚
- è‹¥ `HOST_URL` æŒ‡å‘éæœ¬åœ°åœ°å€ï¼Œéœ€è®¾ç½® `ALLOW_REMOTE_HOST=true` æ‰ä¼šå¯ç”¨è¿œç«¯ Hostï¼ˆå¦åˆ™å¿½ç•¥å¹¶å›é€€æœ¬åœ° Hostï¼‰ã€‚

```json
{
  "scripts": {
    "bench": "ts-node benchmarks/index.ts",
    "bench:profile": "clinic doctor -- ts-node benchmarks/index.ts",
    "bench:flame": "0x -- ts-node benchmarks/index.ts"
  }
}
```

---

## 4. æ€§èƒ½å‰–æ

### 4.1 CPU Profiling

```bash
# ç”Ÿæˆ CPU ç«ç„°å›¾
npm run bench:flame
```

**é¢„æœŸç»“æœ**ï¼š

- `fetch()` å ç”¨å¤§éƒ¨åˆ† CPU æ—¶é—´
- JSON åºåˆ—åŒ–/ååºåˆ—åŒ–å¼€é”€ \u003c 5%
- Terminal é€šä¿¡å¼€é”€ \u003c 10%

### 4.2 Memory Profiling

```bash
# æ£€æµ‹å†…å­˜æ³„æ¼
npm run bench:profile
```

**é¢„æœŸç»“æœ**ï¼š

- ç¨³å®šçš„å†…å­˜å ç”¨ï¼ˆæ— æŒç»­å¢é•¿ï¼‰
- GC åœé¡¿æ—¶é—´ \u003c 10ms

---

## 5. åŸºå‡†æµ‹è¯•ç»“æœï¼ˆé¢„æœŸï¼‰

### 5.1 æœ¬åœ°ç¯å¢ƒï¼ˆMacBook Pro M1ï¼‰

| åœºæ™¯            | RPS  | P50 (ms) | P95 (ms) | P99 (ms) |
| --------------- | ---- | -------- | -------- | -------- |
| Light Load      | 600+ | 15       | 30       | 50       |
| Medium Load     | 250+ | 35       | 80       | 120      |
| Heavy Load      | 60+  | 150      | 300      | 500      |
| 100 Concurrency | -    | 200      | 400      | 600      |

### 5.2 èµ„æºæ¶ˆè€—

- **CPU**: ä»£ç†èŠ‚ç‚¹ \u003c 50%ï¼ˆå•æ ¸ï¼‰
- **Memory**: ä»£ç†èŠ‚ç‚¹ \u003c 200MB
- **Network**: ä¸ HTTP ç›®æ ‡å¸¦å®½ä¸€è‡´

---

## 6. ä¼˜åŒ–å»ºè®®

### 6.1 æ€§èƒ½ç“¶é¢ˆè¯†åˆ«

åŸºäº Profiling ç»“æœï¼Œå¯èƒ½çš„ç“¶é¢ˆï¼š

1. **fetch() æ‰§è¡Œæ—¶é—´**ï¼šå æ®å¤§éƒ¨åˆ†å»¶è¿Ÿï¼Œä¼˜åŒ–ç©ºé—´æœ‰é™
2. **JSON åºåˆ—åŒ–**ï¼šå¤§ body æ—¶å¯èƒ½æˆä¸ºç“¶é¢ˆ
3. **Terminal æ¶ˆæ¯ä¼ è¾“**ï¼šåŒé‡ç½‘ç»œå¼€é”€

### 6.2 ä¼˜åŒ–æ–¹å‘

- **è¿æ¥æ± **ï¼šå¤ç”¨ HTTP è¿æ¥ï¼ˆfetch é»˜è®¤å·²æ”¯æŒï¼‰
- **å‹ç¼©**ï¼šå¯¹å¤§ body å¯ç”¨ gzip
- **ç¼“å­˜**ï¼šå¯¹ GET è¯·æ±‚ç»“æœç¼“å­˜
- **æµå¼ä¼ è¾“**ï¼šä½¿ç”¨ frame æœºåˆ¶æ”¯æŒå¤§æ–‡ä»¶

---

## 7. å‹åŠ›æµ‹è¯•

### 7.1 æé™å¹¶å‘æµ‹è¯•

```typescript
async function stressTest() {
  const concurrency = 500;
  const requests = Array.from({ length: concurrency }, () =>
    requestHTTPProxy(clientTerminal, {
      url: 'http://localhost:3000/light',
    }),
  );

  const results = await Promise.allSettled(requests);
  const succeeded = results.filter((r) => r.status === 'fulfilled').length;
  const failed = results.filter((r) => r.status === 'rejected').length;

  console.log(`Succeeded: ${succeeded}, Failed: ${failed}`);
}
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- 500 å¹¶å‘ä¸‹ï¼ŒæˆåŠŸç‡ \u003e 95%
- æ— æœåŠ¡å´©æºƒæˆ–å†…å­˜æº¢å‡º

---

## 8. å›å½’æµ‹è¯•

### 8.1 æ€§èƒ½åŸºçº¿

å»ºç«‹æ€§èƒ½åŸºçº¿ï¼Œæ¯æ¬¡ä»£ç å˜æ›´åè¿è¡Œ benchmarkï¼š

```bash
npm run bench \u003e benchmarks/baseline.txt
```

### 8.2 æ€§èƒ½å›å½’æ£€æµ‹

å¯¹æ¯”å½“å‰ç»“æœä¸ baselineï¼š

- RPS ä¸‹é™ \u003e 10%ï¼š**è­¦å‘Š**
- RPS ä¸‹é™ \u003e 20%ï¼š**é˜»å¡**

---

## 9. éªŒæ”¶æ ‡å‡†

- [ ] è½»é‡çº§è¯·æ±‚ RPS \u003e 500
- [ ] ä¸­ç­‰è´Ÿè½½ RPS \u003e 200
- [ ] 100 å¹¶å‘ P95 \u003c 500ms
- [ ] Selector å¾®åŸºå‡†ï¼šS1/S2/S3/S4 å‡æ»¡è¶³å¯¹åº” RPS é˜ˆå€¼
- [ ] æ— å†…å­˜æ³„æ¼ï¼ˆ24 å°æ—¶å‹æµ‹ï¼‰
- [ ] CPU å ç”¨ \u003c 50%ï¼ˆå•æ ¸ï¼‰

---

**ä¸‹ä¸€æ­¥**ï¼š

- å®ç° benchmark è„šæœ¬
- å»ºç«‹æ€§èƒ½åŸºçº¿
- é›†æˆåˆ° CI/CDï¼ˆæ¯æ¬¡ PR è¿è¡Œï¼‰
